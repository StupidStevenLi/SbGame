server:
  port: 7080

spring:
  mail:
    port: 465
    # 你的邮箱，发邮件的邮箱
    username: artist.li@qq.com
    # 你的授权码，邮箱里面设置->POP3/SMTP/IMAP
    password: mxifqkkmplrlebjg
    host: smtp.qq.com
    properties:
      mail:
        smtp:
          auth: true
          socketFactory:
            class: javax.net.ssl.SSLSocketFactory
            port: 465
          starttls:
            enable: true
            require: true
          timeout: 2000
  thymeleaf:
    prefix: classpath:/templates/
    # suffix: .html
  application:
    name: SbGame
  datasource:
    username: root
    password: 142536
    url: jdbc:mysql://localhost:3306/mybatis_example
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    #type可以指定数据源类型jdbc:mysql://localhost:3306/?user=root   mybatis?useUnicode=true&characterEncoding=utf-8&serverTimezone=GMT
  data:
    redis:
      host: 127.0.0.1
      port: 6379

  kafka:
    bootstrap-servers: 127.0.0.1:9092

    producer:
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      key-serializer: org.apache.kafka.common.serialization.StringSerializer

    consumer:
      properties:
        spring:
          json:
            trusted:
              packages: com.artist.sbgame.entity

        # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        session:
          timeout:
            ms: 120000
        # 消费请求超时时间
        request:
          timeout:
            ms: 180000
        # 默认的消费组ID
        group:
          id: defaultConsumerGroup

      # 是否自动提交offset
      enable-auto-commit: true
      # 提交offset延时(接收到消息后多久提交offset)
      auto-commit-interval: 1000
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # Kafka提供的序列化和反序列化类
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      # 批量消费每次最多消费多少条消息
      max-poll-records: 500

    listener:
      # 消费端监听的topic不存在时，项目启动会报错(关掉)
      missing-topics-fatal: false
      # 设置批量消费
      type: batch

#  kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test-topic2 --from-beginning

mybatis:
  configuration: # setting配置
    auto-mapping-behavior: full
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl
  type-aliases-package: com.artist.sbgame.entity # 配置别名
  mapper-locations: classpath:/mybatis/*.xml # mapperxml位置

#日志配置
logging:
  config: classpath:logback-spring.xml  #指定项目启动的时，读取logback-spring.xml日志配置文件,文件名最好不要使用logback.xml
  #  level: #配置指定包的路径下应用程序的日志记录和日志级别。
  #    root: info
  #    org.springframework: warn
  file:
    path: src/main/resources/LoggerInfoFile
    #D:\sinux_2023\project\phm\724_3\exe\logs #设置日志输出路径
    name: LoggerInfo.log #设置日志文件的名称

TEST_TOPIC: test-topic
SLEEP_TIME: 500
IdInDebtRedis: IdInDebtRedis
Mail_TemplatePath: templates/mail_template.ftl
Soul_BillBookPath: src/main/resources/static/images/soul.jpg

# 提交，睡大觉